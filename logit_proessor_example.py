"""
Learned Bloat Axis Logit Processor

Generated by Bloat Axis GEPA on 2026-01-21T23:06:06.498883

This processor applies learned penalties to reduce verbosity in worker responses
while maintaining correctness.

Usage with SGLang:
    from learned_logit_processor import LearnedBloatAxisProcessor
    
    # In your generate call:
    extra_body={
        "custom_logit_processor": LearnedBloatAxisProcessor().to_str(),
        "custom_params": LearnedBloatAxisProcessor.get_default_params(),
    }
"""

import torch
from sglang.srt.sampling.custom_logit_processor import CustomLogitProcessor


class LearnedBloatAxisProcessor(CustomLogitProcessor):
    """
    SGLang-compatible logit processor with learned bloat-axis penalties.
    
    Discovered Axes:
        1. preamble: penalty=2.0, condition=early_phase ({'max_t': 48}), phrases=3
        2. hedging: penalty=2.0, condition=always, phrases=3
        3. list_markers: penalty=2.0, condition=after_newline, phrases=3
        4. generic_phrases: penalty=2.0, condition=always, phrases=3
    
    Configuration:
        - min_new_tokens: 48
        - total_axes: 4
    """
    
    # Learned configuration
    AXES_CONFIG = [
        {
            "name": "preamble",
            "phrases": [
                "The cash flow figures for operating, investing, and financing activities for FY2023 are not explicitly stated in the provided document excerpt.",
                "The current assets are not explicitly mentioned in the provided text.",
                "The relevant financial metrics or performance indicators for a bank were not explicitly mentioned in the provided text."
            ],
            "token_ids": [
                12032,
                6530,
                6020,
                50565,
                12678,
                34824,
                264,
                11,
                13,
                527,
                3984,
                18,
                21650,
                279,
                539,
                26012,
                1820,
                1051,
                304,
                53041,
                6201,
                5178,
                2366,
                8515,
                323,
                10565,
                2246,
                29642,
                9932,
                1495,
                11224,
                7640,
                477,
                1510,
                9959,
                369,
                17150
            ],
            "condition": {
                "type": "early_phase",
                "max_t": 48
            },
            "penalty": 2.0
        },
        {
            "name": "hedging",
            "phrases": [
                "However, we can infer some information about the bank's performance and operations.",
                "However, the exact amount is not specified.",
                "However, it is common to find this information in the balance sheet section of financial statements."
            ],
            "token_ids": [
                6020,
                649,
                11,
                13,
                8335,
                3857,
                279,
                922,
                539,
                420,
                1063,
                304,
                433,
                24499,
                5300,
                4279,
                311,
                6201,
                5178,
                315,
                11071,
                3392,
                323,
                584,
                596,
                1505,
                12518,
                4839,
                2038,
                374,
                98936,
                7677
            ],
            "condition": {
                "type": "always"
            },
            "penalty": 2.0
        },
        {
            "name": "list_markers",
            "phrases": [
                "None",
                "No specific financial metrics or performance indicators relevant to a bank are mentioned in the provided text.",
                "No financial metrics or performance indicators specific to banking operations and profitability were found in the provided text."
            ],
            "token_ids": [
                6020,
                34824,
                264,
                13,
                527,
                3984,
                279,
                2201,
                1051,
                3230,
                304,
                6836,
                311,
                6201,
                5178,
                323,
                9932,
                1495,
                23641,
                477,
                1766,
                9959,
                63336,
                7677,
                17150
            ],
            "condition": {
                "type": "after_newline"
            },
            "penalty": 2.0
        },
        {
            "name": "generic_phrases",
            "phrases": [
                "Unfortunately, the provided text does not contain explicit values for net interest margin, return on assets, return on equity, and efficiency ratio.",
                "The task requires extracting financial metrics or performance indicators relevant to a bank, focusing on metrics specific to banking operations and profitability.",
                "The text does not explicitly mention financial metrics such as net interest margin, return on assets, return on equity, or efficiency ratio."
            ],
            "token_ids": [
                12032,
                21760,
                2819,
                6020,
                389,
                34824,
                3465,
                264,
                11,
                11275,
                13,
                15374,
                17150,
                3984,
                21650,
                6420,
                279,
                539,
                1820,
                3230,
                4272,
                1587,
                311,
                439,
                6201,
                5178,
                7612,
                323,
                11720,
                11595,
                1495,
                471,
                23641,
                60508,
                477,
                359,
                9959,
                63336,
                25452,
                369,
                2802,
                4850,
                1778,
                7677,
                6782
            ],
            "condition": {
                "type": "always"
            },
            "penalty": 2.0
        }
    ]
    
    # Pre-computed token ID sets by condition type
    EARLY_PHASE_TOKEN_IDS = set([11, 13, 18, 264, 279, 304, 323, 369, 477, 527, 539, 1051, 1495, 1510, 1820, 2246, 2366, 3984, 5178, 6020, 6201, 6530, 7640, 8515, 9932, 9959, 10565, 11224, 12032, 12678, 17150, 21650, 26012, 29642, 34824, 50565, 53041])
    ALWAYS_TOKEN_IDS = set([11, 13, 264, 279, 304, 311, 315, 323, 359, 369, 374, 389, 420, 433, 439, 471, 477, 539, 584, 596, 649, 922, 1063, 1495, 1505, 1587, 1778, 1820, 2038, 2802, 2819, 3230, 3392, 3465, 3857, 3984, 4272, 4279, 4839, 4850, 5178, 5300, 6020, 6201, 6420, 6782, 7612, 7677, 8335, 9959, 11071, 11275, 11595, 11720, 12032, 12518, 15374, 17150, 21650, 21760, 23641, 24499, 25452, 34824, 60508, 63336, 98936])
    AFTER_NEWLINE_TOKEN_IDS = set([13, 264, 279, 304, 311, 323, 477, 527, 1051, 1495, 1766, 2201, 3230, 3984, 5178, 6020, 6201, 6836, 7677, 9932, 9959, 17150, 23641, 34824, 63336])
    WHITELIST_TOKEN_IDS = set()
    
    # Learned penalties
    EARLY_PHASE_PENALTY = 2.0
    ALWAYS_PENALTY = 2.0
    AFTER_NEWLINE_PENALTY = 2.0
    
    # Anti-truncation settings
    MIN_NEW_TOKENS = 48
    EOS_BONUS_AFTER_MIN = 1.2
    INTRO_WINDOW = 48
    
    @classmethod
    def get_default_params(cls) -> dict:
        """Get default custom_params for this processor."""
        return {
            "eos_token_id": 128001,  # Llama-3 default
            "min_new_tokens": cls.MIN_NEW_TOKENS,
            "current_len": 0,
            "eos_bonus_after_min": cls.EOS_BONUS_AFTER_MIN,
            "intro_window": cls.INTRO_WINDOW,
            "intro_penalty": cls.EARLY_PHASE_PENALTY,
            "always_penalty": cls.ALWAYS_PENALTY,
            "list_penalty": cls.AFTER_NEWLINE_PENALTY,
            "intro_token_ids": list(cls.EARLY_PHASE_TOKEN_IDS),
            "always_token_ids": list(cls.ALWAYS_TOKEN_IDS),
            "list_token_ids": list(cls.AFTER_NEWLINE_TOKEN_IDS),
            "whitelist_token_ids": list(cls.WHITELIST_TOKEN_IDS),
        }
    
    def __call__(self, logits, custom_param_list):
        """
        Apply learned bloat-axis penalties at each decoding step.
        
        Args:
            logits: (batch_size, vocab_size) tensor of next-token logits
            custom_param_list: List of dicts with per-request parameters
        """
        assert logits.shape[0] == len(custom_param_list)
        
        for i, p in enumerate(custom_param_list):
            # Extract parameters
            eos_token_id = int(p.get("eos_token_id", 128001))
            min_new_tokens = int(p.get("min_new_tokens", self.MIN_NEW_TOKENS))
            current_len = int(p.get("current_len", 0))
            
            # Penalty values
            eos_bonus_after_min = float(p.get("eos_bonus_after_min", self.EOS_BONUS_AFTER_MIN))
            intro_window = int(p.get("intro_window", self.INTRO_WINDOW))
            intro_penalty = float(p.get("intro_penalty", self.EARLY_PHASE_PENALTY))
            always_penalty = float(p.get("always_penalty", self.ALWAYS_PENALTY))
            list_penalty = float(p.get("list_penalty", self.AFTER_NEWLINE_PENALTY))
            
            # Token ID sets (use class defaults if not provided in params)
            intro_token_ids = set(p.get("intro_token_ids", list(self.EARLY_PHASE_TOKEN_IDS)))
            always_token_ids = set(p.get("always_token_ids", list(self.ALWAYS_TOKEN_IDS)))
            list_token_ids = set(p.get("list_token_ids", list(self.AFTER_NEWLINE_TOKEN_IDS)))
            whitelist_ids = set(p.get("whitelist_token_ids", list(self.WHITELIST_TOKEN_IDS)))
            
            newline_token_ids = p.get("newline_token_ids", [198, 628])  # Common newline tokens
            last_token_id = p.get("last_token_id", None)
            
            # 1) Anti-truncation: block EOS before min_new_tokens
            if current_len < min_new_tokens:
                logits[i, eos_token_id] = -1e9
            else:
                logits[i, eos_token_id] += eos_bonus_after_min
            
            # 2) Always-on penalties (respecting whitelist)
            if always_token_ids and always_penalty > 0:
                for tid in always_token_ids:
                    if tid not in whitelist_ids:
                        logits[i, tid] -= always_penalty
            
            # 3) Early-phase penalties (preamble/intro suppression)
            if current_len < intro_window and intro_token_ids and intro_penalty > 0:
                for tid in intro_token_ids:
                    if tid not in whitelist_ids:
                        logits[i, tid] -= intro_penalty
            
            # 4) After-newline penalties (list markers, etc.)
            if list_token_ids and list_penalty > 0:
                for tid in list_token_ids:
                    if tid not in whitelist_ids:
                        logits[i, tid] -= list_penalty
            
            # 5) Extra penalty after actual newlines
            if last_token_id is not None and int(last_token_id) in newline_token_ids:
                for tid in list_token_ids:
                    if tid not in whitelist_ids:
                        logits[i, tid] -= (list_penalty + 1.0)
        
        return logits


# Standalone configuration export
AXES_CONFIG = LearnedBloatAxisProcessor.AXES_CONFIG
